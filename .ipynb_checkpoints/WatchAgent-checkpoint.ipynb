{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch a Smart Agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Start the Environment for Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import os\n",
    "import time\n",
    "\n",
    "from agent import Agent\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def rgb2gray(rgb, norm=True):\n",
    "        # rgb image -> gray [0, 1]\n",
    "    gray = np.dot(rgb[..., :], [0.299, 0.587, 0.114])\n",
    "    if norm:\n",
    "        # normalize\n",
    "        gray = gray / 128. - 1.\n",
    "    return gray\n",
    "\n",
    "seed = 0\n",
    "img_stack = 4\n",
    "action_repeat = 10\n",
    "env = gym.make('CarRacing-v0', verbose=0)\n",
    "state = env.reset()\n",
    "reward_threshold = env.spec.reward_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper():\n",
    "    \"\"\"\n",
    "    Environment wrapper for CarRacing \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env  \n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "        self.av_r = self.reward_memory()\n",
    "\n",
    "        self.die = False\n",
    "        img_rgb = env.reset()\n",
    "        img_gray = rgb2gray(img_rgb)\n",
    "        self.stack = [img_gray] * img_stack  # four frames for decision\n",
    "        return np.array(self.stack)\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        for i in range(action_repeat):\n",
    "            img_rgb, reward, die, _ = env.step(action)\n",
    "            # don't penalize \"die state\"\n",
    "            if die:\n",
    "                reward += 100\n",
    "            # green penalty\n",
    "            if np.mean(img_rgb[:, :, 1]) > 185.0:\n",
    "                reward -= 0.05\n",
    "            total_reward += reward\n",
    "            # if no reward recently, end the episode\n",
    "            done = True if self.av_r(reward) <= -0.1 else False\n",
    "            if done or die:\n",
    "                break\n",
    "        img_gray = rgb2gray(img_rgb)\n",
    "        self.stack.pop(0)\n",
    "        self.stack.append(img_gray)\n",
    "        assert len(self.stack) == img_stack\n",
    "        return np.array(self.stack), total_reward, done, die\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def reward_memory():\n",
    "        # record reward for last 100 steps\n",
    "        count = 0\n",
    "        length = 100\n",
    "        history = np.zeros(length)\n",
    "\n",
    "        def memory(reward):\n",
    "            nonlocal count\n",
    "            history[count] = reward\n",
    "            count = (count + 1) % length\n",
    "            return np.mean(history)\n",
    "\n",
    "        return memory\n",
    "    \n",
    "agent = Agent(device)\n",
    "\n",
    "env_wrap = Wrapper(env)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(agent, directory, filename):\n",
    "    agent.net.load_state_dict(torch.load(os.path.join(directory,filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import os\n",
    "\n",
    "def play(env, agent, n_episodes):\n",
    "    state = env_wrap.reset()\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env_wrap.reset()        \n",
    "        score = 0\n",
    "        \n",
    "        time_start = time.time()\n",
    "        \n",
    "        while True:\n",
    "            action, a_logp = agent.select_action(state)\n",
    "            env.render()\n",
    "            next_state, reward, done, die = env_wrap.step( \\\n",
    "                action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            if done or die:\n",
    "                break \n",
    "\n",
    "        s = (int)(time.time() - time_start)\n",
    "        \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "\n",
    "        print('Episode {}\\tAverage Score: {:.2f},\\tScore: {:.2f} \\tTime: {:02}:{:02}:{:02}'\\\n",
    "                  .format(i_episode, np.mean(scores_deque), score, s//3600, s%3600//60, s%60))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 49.17,\tScore: 49.17 \tTime: 00:00:03\n",
      "Episode 2\tAverage Score: 242.92,\tScore: 436.67 \tTime: 00:00:12\n",
      "Episode 3\tAverage Score: 288.93,\tScore: 380.95 \tTime: 00:00:11\n",
      "Episode 4\tAverage Score: 282.13,\tScore: 261.75 \tTime: 00:00:10\n",
      "Episode 5\tAverage Score: 249.01,\tScore: 116.51 \tTime: 00:00:07\n"
     ]
    }
   ],
   "source": [
    "load(agent, 'dir_chk', 'model_weights_0.pth')\n",
    "play(env, agent, n_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 364.38,\tScore: 364.38 \tTime: 00:00:10\n",
      "Episode 2\tAverage Score: 478.91,\tScore: 593.44 \tTime: 00:00:11\n",
      "Episode 3\tAverage Score: 343.40,\tScore: 72.38 \tTime: 00:00:03\n",
      "Episode 4\tAverage Score: 421.84,\tScore: 657.14 \tTime: 00:00:11\n",
      "Episode 5\tAverage Score: 387.87,\tScore: 252.00 \tTime: 00:00:07\n"
     ]
    }
   ],
   "source": [
    "load(agent, 'dir_chk', 'model_weights_400.pth')\n",
    "play(env, agent, n_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 727.27,\tScore: 727.27 \tTime: 00:00:11\n",
      "Episode 2\tAverage Score: 735.01,\tScore: 742.75 \tTime: 00:00:11\n",
      "Episode 3\tAverage Score: 605.58,\tScore: 346.72 \tTime: 00:00:09\n",
      "Episode 4\tAverage Score: 622.98,\tScore: 675.16 \tTime: 00:00:12\n",
      "Episode 5\tAverage Score: 641.44,\tScore: 715.30 \tTime: 00:00:11\n"
     ]
    }
   ],
   "source": [
    "load(agent, 'dir_chk', 'model_weights_600.pth')\n",
    "play(env, agent, n_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 946.97,\tScore: 946.97 \tTime: 00:00:11\n",
      "Episode 2\tAverage Score: 883.74,\tScore: 820.51 \tTime: 00:00:11\n",
      "Episode 3\tAverage Score: 729.25,\tScore: 420.27 \tTime: 00:00:07\n",
      "Episode 4\tAverage Score: 799.59,\tScore: 1010.60 \tTime: 00:00:09\n",
      "Episode 5\tAverage Score: 830.48,\tScore: 954.02 \tTime: 00:00:11\n"
     ]
    }
   ],
   "source": [
    "load(agent, 'dir_chk', 'model_weights_800.pth')\n",
    "play(env, agent, n_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 975.52,\tScore: 975.52 \tTime: 00:00:11\n",
      "Episode 2\tAverage Score: 980.57,\tScore: 985.61 \tTime: 00:00:11\n",
      "Episode 3\tAverage Score: 708.28,\tScore: 163.71 \tTime: 00:00:09\n",
      "Episode 4\tAverage Score: 733.39,\tScore: 808.72 \tTime: 00:00:11\n",
      "Episode 5\tAverage Score: 779.57,\tScore: 964.29 \tTime: 00:00:11\n"
     ]
    }
   ],
   "source": [
    "load(agent, 'dir_chk', 'model_weights_830.pth')\n",
    "play(env, agent, n_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 988.81,\tScore: 988.81 \tTime: 00:00:11\n",
      "Episode 2\tAverage Score: 994.75,\tScore: 1000.70 \tTime: 00:00:11\n",
      "Episode 3\tAverage Score: 996.60,\tScore: 1000.30 \tTime: 00:00:11\n",
      "Episode 4\tAverage Score: 837.21,\tScore: 359.05 \tTime: 00:00:09\n",
      "Episode 5\tAverage Score: 831.76,\tScore: 809.94 \tTime: 00:00:12\n"
     ]
    }
   ],
   "source": [
    "load(agent, 'dir_chk', 'model_weights_870.pth')\n",
    "play(env, agent, n_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tAverage Score: 863.87,\tScore: 863.87 \tTime: 00:00:10\n",
      "Episode 2\tAverage Score: 882.57,\tScore: 901.27 \tTime: 00:00:12\n",
      "Episode 3\tAverage Score: 858.32,\tScore: 809.82 \tTime: 00:00:11\n",
      "Episode 4\tAverage Score: 822.73,\tScore: 715.98 \tTime: 00:00:12\n",
      "Episode 5\tAverage Score: 856.83,\tScore: 993.24 \tTime: 00:00:11\n"
     ]
    }
   ],
   "source": [
    "load(agent, 'dir_chk', 'model_weights_900.pth')\n",
    "play(env, agent, n_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
