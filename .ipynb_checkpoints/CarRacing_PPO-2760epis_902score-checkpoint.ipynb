{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DoubleW\\miniconda3\\envs\\robot\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env.action_space.shape:  (3,)\n",
      "reward_threshold 900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Beta\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "from agent import Agent, img_stack\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ', device)\n",
    "\n",
    "seed = 0 \n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "action_repeat = 10\n",
    "env = gym.make('CarRacing-v0', verbose=0)\n",
    "state = env.reset()\n",
    "print('env.action_space.shape: ', env.action_space.shape)\n",
    "reward_threshold = env.spec.reward_threshold\n",
    "print('reward_threshold', reward_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame.shape:  (96, 96, 3)\n",
      "img.shape:  (96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show what a preprocessed image looks like\n",
    "frame, _, _, _ = env.step(np.array([2., 1., 1.]))\n",
    "\n",
    "print('frame.shape: ', frame.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(frame)\n",
    "plt.title('original image')\n",
    "\n",
    "#-------------------------------#\n",
    "\n",
    "def rgb2gray(rgb, norm=True):\n",
    "        # rgb image -> gray [0, 1]\n",
    "    gray = np.dot(rgb[..., :], [0.299, 0.587, 0.114])\n",
    "    if norm:\n",
    "        # normalize\n",
    "        gray = gray / 128. - 1.\n",
    "    return gray\n",
    "\n",
    "img_gray = rgb2gray(frame)\n",
    "\n",
    "#-------------------------------# \n",
    "plt.subplot(1,2,2)\n",
    "plt.title('preprocessed image')\n",
    "\n",
    "print('img.shape: ', img_gray.shape)\n",
    "\n",
    "# 96 x 96 black and white image\n",
    "plt.imshow(img_gray, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Class  Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper():\n",
    "    \"\"\"\n",
    "    Environment wrapper for CarRacing \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env  \n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "        self.av_r = self.reward_memory()\n",
    "\n",
    "        self.die = False\n",
    "        img_rgb = env.reset()\n",
    "        img_gray = rgb2gray(img_rgb)\n",
    "        self.stack = [img_gray] * img_stack  # four frames for decision\n",
    "        return np.array(self.stack)\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        for i in range(action_repeat):\n",
    "            img_rgb, reward, die, _ = env.step(action)\n",
    "            # don't penalize \"die state\"\n",
    "            if die:\n",
    "                reward += 100\n",
    "            # green penalty\n",
    "            if np.mean(img_rgb[:, :, 1]) > 185.0:\n",
    "                reward -= 0.05\n",
    "            total_reward += reward\n",
    "            # if no reward recently, end the episode\n",
    "            done = True if self.av_r(reward) <= -0.1 else False\n",
    "            if done or die:\n",
    "                break\n",
    "        img_gray = rgb2gray(img_rgb)\n",
    "        self.stack.pop(0)\n",
    "        self.stack.append(img_gray)\n",
    "        assert len(self.stack) == img_stack\n",
    "        return np.array(self.stack), total_reward, done, die\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def reward_memory():\n",
    "        # record reward for last 100 steps\n",
    "        count = 0\n",
    "        length = 100\n",
    "        history = np.zeros(length)\n",
    "\n",
    "        def memory(reward):\n",
    "            nonlocal count\n",
    "            history[count] = reward\n",
    "            count = (count + 1) % length\n",
    "            return np.mean(history)\n",
    "\n",
    "        return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(agent, directory, filename, suffix):\n",
    "    torch.save(agent.net.state_dict(), '%s/%s_%s.pth' % (directory, filename, suffix))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep. 0, Ep.Timesteps 100, Score: 87.25, Avg.Score: 87.25, Run.Score 0.87, Time: 00:00:13 \n",
      "Ep. 1, Ep.Timesteps 86, Score: -14.03, Avg.Score: 36.61, Run.Score 0.72, Time: 00:00:22 \n",
      "Ep. 2, Ep.Timesteps 86, Score: -6.30, Avg.Score: 22.30, Run.Score 0.65, Time: 00:00:32 \n",
      "Ep. 3, Ep.Timesteps 94, Score: -17.84, Avg.Score: 12.27, Run.Score 0.47, Time: 00:00:42 \n",
      "Ep. 4, Ep.Timesteps 100, Score: 84.21, Avg.Score: 26.66, Run.Score 1.31, Time: 00:00:53 \n",
      "Ep. 5, Ep.Timesteps 93, Score: -17.81, Avg.Score: 19.24, Run.Score 1.11, Time: 00:01:03 \n",
      "Ep. 6, Ep.Timesteps 75, Score: -19.25, Avg.Score: 13.74, Run.Score 0.91, Time: 00:01:12 \n",
      "Ep. 7, Ep.Timesteps 93, Score: -17.97, Avg.Score: 9.78, Run.Score 0.72, Time: 00:01:23 \n",
      "Ep. 8, Ep.Timesteps 99, Score: -17.95, Avg.Score: 6.70, Run.Score 0.54, Time: 00:01:33 \n",
      "Ep. 9, Ep.Timesteps 97, Score: -17.94, Avg.Score: 4.24, Run.Score 0.35, Time: 00:01:44 \n",
      "Ep. 10, Ep.Timesteps 96, Score: -17.91, Avg.Score: 2.22, Run.Score 0.17, Time: 00:01:54 \n",
      "Ep. 11, Ep.Timesteps 88, Score: -17.99, Avg.Score: 0.54, Run.Score -0.01, Time: 00:02:04 \n",
      "Ep. 12, Ep.Timesteps 100, Score: 79.03, Avg.Score: 6.58, Run.Score 0.78, Time: 00:02:16 \n",
      "Ep. 13, Ep.Timesteps 83, Score: -21.72, Avg.Score: 4.55, Run.Score 0.55, Time: 00:02:25 \n",
      "Ep. 14, Ep.Timesteps 100, Score: 79.51, Avg.Score: 9.55, Run.Score 1.34, Time: 00:02:37 \n",
      "Ep. 15, Ep.Timesteps 92, Score: -21.86, Avg.Score: 7.59, Run.Score 1.11, Time: 00:02:48 \n",
      "Ep. 16, Ep.Timesteps 92, Score: -17.93, Avg.Score: 6.09, Run.Score 0.92, Time: 00:02:57 \n",
      "Ep. 17, Ep.Timesteps 100, Score: 83.03, Avg.Score: 10.36, Run.Score 1.74, Time: 00:03:08 \n",
      "Ep. 18, Ep.Timesteps 94, Score: -28.05, Avg.Score: 8.34, Run.Score 1.44, Time: 00:03:17 \n",
      "Ep. 19, Ep.Timesteps 74, Score: -18.05, Avg.Score: 7.02, Run.Score 1.25, Time: 00:03:25 \n",
      "Ep. 20, Ep.Timesteps 100, Score: 93.85, Avg.Score: 11.15, Run.Score 2.17, Time: 00:03:35 \n",
      "updating\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 270.00 MiB (GPU 0; 2.00 GiB total capacity; 1.10 GiB already allocated; 107.37 MiB free; 21.52 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-79fc767f8738>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_scores_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_scores\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mppo_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-79fc767f8738>\u001b[0m in \u001b[0;36mppo_train\u001b[1;34m(n_episodes, save_every)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_logp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'updating'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Assignment\\Deep-Reinforcement-Learning-Udacity\\CarRacing-From-Pixels-PPO\\agent.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mtarget_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[0madv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_v\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;31m# adv = (adv - adv.mean()) / (adv.std() + 1e-8)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\robot\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Study\\Assignment\\Deep-Reinforcement-Learning-Udacity\\CarRacing-From-Pixels-PPO\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn_base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\robot\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\robot\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\robot\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\robot\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\robot\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 340\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 270.00 MiB (GPU 0; 2.00 GiB total capacity; 1.10 GiB already allocated; 107.37 MiB free; 21.52 MiB cached)"
     ]
    }
   ],
   "source": [
    "agent = Agent(device)\n",
    "\n",
    "env_wrap = Wrapper(env)\n",
    "\n",
    "limits = [200, 400, 600, 800, 830, 870, 900]\n",
    "\n",
    "def return_suffix(j):\n",
    "    suf = '0'\n",
    "    for i in range(len(limits)-1):\n",
    "        if j > limits[i] and j < limits[i+1]:\n",
    "            suf = str(limits[i+1])\n",
    "            break\n",
    "        \n",
    "        i_last = len(limits)-1    \n",
    "        if  j > limits[i_last]:\n",
    "            suf = str(limits[i_last])\n",
    "            break\n",
    "    return suf           \n",
    "\n",
    "\n",
    "def ppo_train(n_episodes=5000, save_every=500):\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_array = []\n",
    "    avg_scores_array = []    \n",
    "\n",
    "    timestep_after_last_save = 0\n",
    "    \n",
    "    time_start = time.time()\n",
    "\n",
    "    running_score = 0\n",
    "    state = env_wrap.reset()\n",
    "    \n",
    "    i_lim = 0\n",
    "    \n",
    "    for i_episode in range(n_episodes):\n",
    "        \n",
    "        timestep = 0\n",
    "        total_reward = 0\n",
    "        \n",
    "        ## score = 0\n",
    "        state = env_wrap.reset()\n",
    "\n",
    "        while True:    \n",
    "            \n",
    "            action, a_logp = agent.select_action(state)\n",
    "            next_state, reward, done, die = env_wrap.step( \n",
    "                action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
    "\n",
    "            if agent.store((state, action, a_logp, reward, next_state)):\n",
    "                print('updating')\n",
    "                agent.update()\n",
    "            \n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            timestep += 1  \n",
    "            timestep_after_last_save += 1\n",
    "            \n",
    "            if done or die:\n",
    "                break\n",
    "                \n",
    "        running_score = running_score * 0.99 + total_reward * 0.01\n",
    "\n",
    "        scores_deque.append(total_reward)\n",
    "        scores_array.append(total_reward)\n",
    "\n",
    "        avg_score = np.mean(scores_deque)\n",
    "        avg_scores_array.append(avg_score)\n",
    "        \n",
    "        s = (int)(time.time() - time_start)        \n",
    "        print('Ep. {}, Ep.Timesteps {}, Score: {:.2f}, Avg.Score: {:.2f}, Run.Score {:.2f}, \\\n",
    "Time: {:02}:{:02}:{:02} '\\\n",
    "            .format(i_episode, timestep, \\\n",
    "                    total_reward, avg_score, running_score, s//3600, s%3600//60, s%60))  \n",
    "       \n",
    "        \n",
    "        # Save episode if more than save_every=500 timesteps\n",
    "        if timestep_after_last_save >= save_every:\n",
    "\n",
    "            timestep_after_last_save %= save_every            \n",
    "            suf = return_suffix(avg_score)\n",
    "            save(agent, 'dir_chk', 'model_weights', suf)\n",
    "            \n",
    "        if np.mean(scores_deque) > reward_threshold:\n",
    "            print(\"Solved environment! Running score is {:.2f}, Avg.Score: {:.2f} !\" \\\n",
    "                  .format(running_score, avg_score))\n",
    "            break\n",
    "            \n",
    "    return scores_array, avg_scores_array    \n",
    "            \n",
    "scores, avg_scores  = ppo_train()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(agent, 'dir_chk', 'model_weights', '902')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('length of scores: ', len(scores), ', len of avg_scores: ', len(avg_scores))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores, label=\"Score\")\n",
    "plt.plot(np.arange(1, len(avg_scores)+1), avg_scores, label=\"Avg on 100 episodes\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1)) \n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episodes #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
